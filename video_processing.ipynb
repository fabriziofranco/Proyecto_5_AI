{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import video_colorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"landscapes_128_arch1\"\n",
    "video_path=\"videos/forest_3.mp4\"\n",
    "filename = \"forest_3\"\n",
    "height = width = 256\n",
    "duration = 13\n",
    "FPS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The sum of train_size and test_size = 420, should be smaller than the number of samples 411. Reduce test_size and/or train_size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/maorroizmangheiler/Documents/UTEC/2022-1/Inteligencia Artificial/Proyecto_5_AI/video_processing.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maorroizmangheiler/Documents/UTEC/2022-1/Inteligencia%20Artificial/Proyecto_5_AI/video_processing.ipynb#ch0000002?line=0'>1</a>\u001b[0m video_colorization\u001b[39m.\u001b[39;49mcolorize_video(model_name, video_path, filename, height\u001b[39m=\u001b[39;49mheight, width\u001b[39m=\u001b[39;49mwidth, duration\u001b[39m=\u001b[39;49mduration, frames\u001b[39m=\u001b[39;49mFPS)\n",
      "File \u001b[0;32m~/Documents/UTEC/2022-1/Inteligencia Artificial/Proyecto_5_AI/video_colorization.py:165\u001b[0m, in \u001b[0;36mcolorize_video\u001b[0;34m(model_name, video_path, filename, height, width, duration, frames)\u001b[0m\n\u001b[1;32m    163\u001b[0m resize_all_images_and_colorized(data_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m/tmp/\u001b[39m\u001b[39m\"\u001b[39m,data_dst\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m/color/\u001b[39m\u001b[39m\"\u001b[39m,color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m resize_all_images_and_colorized(data_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m/tmp/\u001b[39m\u001b[39m\"\u001b[39m,data_dst\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m/gray/\u001b[39m\u001b[39m\"\u001b[39m,color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m colorize_grays(model_name,video_path, filename, height\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, width\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, duration\u001b[39m=\u001b[39;49mduration, frames\u001b[39m=\u001b[39;49mframes)\n\u001b[1;32m    166\u001b[0m images_to_video(data_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m/color/\u001b[39m\u001b[39m\"\u001b[39m, data_dst\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, video_name\u001b[39m=\u001b[39mfilename\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_color.avi\u001b[39m\u001b[39m\"\u001b[39m, frames \u001b[39m=\u001b[39m frames) \u001b[39m#generar video a color resize\u001b[39;00m\n\u001b[1;32m    167\u001b[0m images_to_video(data_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m/gray/\u001b[39m\u001b[39m\"\u001b[39m, data_dst\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, video_name\u001b[39m=\u001b[39mfilename\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_gray.avi\u001b[39m\u001b[39m\"\u001b[39m, frames \u001b[39m=\u001b[39m frames) \u001b[39m#generar video en blanco y negro resize\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UTEC/2022-1/Inteligencia Artificial/Proyecto_5_AI/video_colorization.py:113\u001b[0m, in \u001b[0;36mcolorize_grays\u001b[0;34m(model_name, video_path, filename, height, width, duration, frames)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcolorize_grays\u001b[39m(model_name,video_path, filename, height\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, width\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, duration\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m, frames\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m):\n\u001b[1;32m    112\u001b[0m     img_transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mToTensor()]) \n\u001b[0;32m--> 113\u001b[0m     dataset \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mLabDataSet(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mvideos/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfilename\u001b[39m}\u001b[39;49;00m\u001b[39m/color\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    114\u001b[0m                 img_transform, train_size\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(duration\u001b[39m*\u001b[39;49mframes\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m), test_size\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(duration\u001b[39m*\u001b[39;49mframes\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m), height\u001b[39m=\u001b[39;49mheight, width\u001b[39m=\u001b[39;49mwidth, seed\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[1;32m    116\u001b[0m     model \u001b[39m=\u001b[39m model_1\u001b[39m.\u001b[39mAutoencoder()\n\u001b[1;32m    117\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m/model.pt\u001b[39m\u001b[39m'\u001b[39m, map_location\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m) ))\n",
      "File \u001b[0;32m~/Documents/UTEC/2022-1/Inteligencia Artificial/Proyecto_5_AI/utils.py:30\u001b[0m, in \u001b[0;36mLabDataSet.__init__\u001b[0;34m(self, main_dir, transform, train_size, test_size, height, width, seed)\u001b[0m\n\u001b[1;32m     27\u001b[0m all_imgs \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(main_dir)\n\u001b[1;32m     28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_imgs \u001b[39m=\u001b[39m natsorted(all_imgs)\n\u001b[0;32m---> 30\u001b[0m train_idx, val_idx \u001b[39m=\u001b[39m train_test_split(\u001b[39mlist\u001b[39;49m(\u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtotal_imgs))), train_size\u001b[39m=\u001b[39;49mtrain_size, test_size\u001b[39m=\u001b[39;49mtest_size, random_state\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_set \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m train_idx ]\n\u001b[1;32m     33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_set \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m val_idx ]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2420\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2417\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[1;32m   2419\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> 2420\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2421\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[1;32m   2422\u001b[0m )\n\u001b[1;32m   2424\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m   2425\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2088\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2085\u001b[0m     n_test \u001b[39m=\u001b[39m n_samples \u001b[39m-\u001b[39m n_train\n\u001b[1;32m   2087\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m+\u001b[39m n_test \u001b[39m>\u001b[39m n_samples:\n\u001b[0;32m-> 2088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2089\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe sum of train_size and test_size = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mshould be smaller than the number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msamples \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. Reduce test_size and/or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2092\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrain_size.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_train \u001b[39m+\u001b[39m n_test, n_samples)\n\u001b[1;32m   2093\u001b[0m     )\n\u001b[1;32m   2095\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[1;32m   2097\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: The sum of train_size and test_size = 420, should be smaller than the number of samples 411. Reduce test_size and/or train_size."
     ]
    }
   ],
   "source": [
    "video_colorization.colorize_video(model_name, video_path, filename, height=height, width=width, duration=duration, frames=FPS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60ba1e9c20a97bab95adc8fa7cd7536eabf7ae0f08621d987aa706dba1e5c7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
